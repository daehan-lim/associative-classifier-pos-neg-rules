{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "# class 0에서 랜덤하게 1100개를 선택해서 사용\n",
    "import csv\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import random\n",
    "from mlxtend.frequent_patterns import apriori"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4615\n"
     ]
    }
   ],
   "source": [
    "with open('data/dataset.csv', 'r') as file:\n",
    "        data_set = [list(filter(None, row)) for row in csv.reader(file)]\n",
    "\n",
    "print(len(data_set))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4615, 149)\n"
     ]
    }
   ],
   "source": [
    "te = TransactionEncoder()\n",
    "te_ary = te.fit_transform(data_set)\n",
    "m_transactions = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "print(m_transactions.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "transactions_0 = pd.DataFrame(\n",
    "            m_transactions[m_transactions['0']].reset_index(drop=True).drop(['1', '0'], axis=1))\n",
    "transactions_1 = pd.DataFrame(\n",
    "            m_transactions[m_transactions['1']].reset_index(drop=True).drop(['1', '0'], axis=1))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "# seeds [0, 10, 35, 42, 123, 456, 789, 101112, 131415, 161718]\n",
    "random.seed(161718)\n",
    "indices = list( range(0, len(transactions_0)) )\n",
    "random.shuffle(indices)\n",
    "transactions_te_0 = transactions_0.iloc[indices[:417],:]\n",
    "#transactions_tr_00 = transactions_0.iloc[indices[417:810],:]\n",
    "transactions_tr_0 = transactions_0.iloc[indices[417:],:]\n",
    "\n",
    "indices = list( range(0, len(transactions_1)) )\n",
    "random.shuffle(indices)\n",
    "transactions_te_1 = transactions_1.iloc[indices[:43],:]\n",
    "transactions_tr_1 = transactions_1.iloc[indices[43:],:]\n",
    "\n",
    "tr_0_ary=(transactions_tr_0.values).astype('int')\n",
    "tr_1_ary=(transactions_tr_1.values).astype('int')\n",
    "\n",
    "#tr_00_ary=(transactions_tr_00.values).astype('int')\n",
    "\n",
    "transactions_tr = pd.concat([transactions_tr_0, transactions_tr_1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4155, 147) 22205\n"
     ]
    }
   ],
   "source": [
    "frequent_items = apriori(transactions_tr, min_support=0.1)\n",
    "print(transactions_tr.shape, len(frequent_items))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "attributes_count = transactions_tr.shape[1]  #number of attributes\n",
    "freq_itemsets_count = len(frequent_items)   #number of frequent items\n",
    "freq_itemsets = frequent_items['itemsets']\n",
    "freq_itemsets_matrix = [list(x) for x in freq_itemsets]\n",
    "attributes_contained_in_freq_items= np.zeros((attributes_count, freq_itemsets_count))\n",
    "for i in range(len(frequent_items)):\n",
    "    attributes_contained_in_freq_items[freq_itemsets_matrix[i],i]=1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class rules 22205\n"
     ]
    }
   ],
   "source": [
    "#lift\n",
    "cp_attr_contained_freq_items = copy.deepcopy(attributes_contained_in_freq_items)\n",
    "freq_count_per_trans_0 = np.matmul(tr_0_ary, attributes_contained_in_freq_items)\n",
    "freq_count_per_trans_1 = np.matmul(tr_1_ary, attributes_contained_in_freq_items)\n",
    "# Each element in the matrix indicates the count of how many times the corresponding frequent itemset occurred in the transactions of the corresponding class.\n",
    "\n",
    "item_len = np.sum(attributes_contained_in_freq_items, axis=0) #item length\n",
    "cls0 = np.zeros(freq_itemsets_count)   #frequent_items['support']\n",
    "cls1 = np.zeros(freq_itemsets_count)\n",
    "p = np.zeros(freq_itemsets_count)\n",
    "conf = np.zeros(freq_itemsets_count)\n",
    "c_per_rule = np.zeros(freq_itemsets_count, dtype=int)\n",
    "cnt=0\n",
    "for i in range(freq_count_per_trans_0.shape[1]):\n",
    "    cls0[i] = (freq_count_per_trans_0[:, i] >= item_len[i]).sum() / freq_count_per_trans_0.shape[0]\n",
    "    cls1[i] = (freq_count_per_trans_1[:, i] >= item_len[i]).sum() / freq_count_per_trans_1.shape[0]\n",
    "    p[i] = ((freq_count_per_trans_0[:, i] >= item_len[i]).sum() + (freq_count_per_trans_1[:, i] >= item_len[i]).sum()) / (freq_count_per_trans_0.shape[0] + freq_count_per_trans_1.shape[0])\n",
    "\n",
    "    '''\n",
    "    p: proportion of transactions in which the corresponding frequent itemset appears\n",
    "    it is calculated as the sum of the number of transactions containing the itemset\n",
    "    in both classes (0 and 1) divided by the total number of transactions.\n",
    "\n",
    "    cls0[i]/p[i] is the ratio of the number of transactions in which the itemset appears in class 0 to the total number of transactions in which the itemset appears, regardless of the class. The confidence score indicates the likelihood that the rule's consequent will be present in transactions that contain its antecedent.\n",
    "\n",
    "    The line elif cls0[i]/p[i]<1 and cls1[i]/p[i]>1: is checking whether the confidence of the association rule in question is greater for class 1 than class 0, and whether that confidence is greater than 1.\n",
    "    If the confidence of the rule is less for class 0 than class 1, but the confidence for class 1 is greater than 1, then the rule is said to have a \"class 1\" association, meaning that it is more strongly associated with class 1. In this case, indc[i] is set to 1, indicating that the rule has a class 1 association, and conf[i] is set to the ratio of the support of the rule in class 1 to the overall support of the rule in both classes.\n",
    "    '''\n",
    "\n",
    "    if cls0[i]/p[i]>1:\n",
    "        c_per_rule[i] = 0\n",
    "        conf[i] = cls0[i]/p[i]\n",
    "        cnt = cnt +1\n",
    "    elif cls0[i]/p[i]<1 and cls1[i]/p[i]>1:\n",
    "        c_per_rule[i] = 1\n",
    "        conf[i] = cls1[i]/p[i]\n",
    "        cnt = cnt +1\n",
    "    else:\n",
    "        conf[i]=0\n",
    "        cp_attr_contained_freq_items[:, i]=0\n",
    "        c_per_rule[i] =-1\n",
    "print('class rules', cnt)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rules for class 0: 14704 Rules for class 1: 7501\n",
      "Avg conf for class 0: 1.0494745383338224, Avg conf for class 1: 1.5226197565933932\n",
      "417 5 3\n",
      "43 0 0\n",
      "0.9008142323350622\n",
      "0.7713735987953823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(f\"Rules for class 0: {(c_per_rule == 0).sum()} Rules for class 1: {(c_per_rule == 1).sum()}\")\n",
    "print(f\"Avg conf for class 0: {conf[c_per_rule == 0].mean()}, Avg conf for class 1: {conf[c_per_rule == 1].mean()}\")\n",
    "\n",
    "te_0_ary=(transactions_te_0.values).astype('int')\n",
    "te_1_ary=(transactions_te_1.values).astype('int')\n",
    "\n",
    "#first rule used\n",
    "y_0 = np.matmul(te_0_ary, cp_attr_contained_freq_items)\n",
    "y_1 = np.matmul(te_1_ary, cp_attr_contained_freq_items)\n",
    "# Each element in the matrix indicates the count of how many times the corresponding frequent itemset occurred in the transactions of the corresponding class.\n",
    "\n",
    "pred = np.zeros((y_0.shape[0]+y_1.shape[0],2))\n",
    "cnt0=0\n",
    "cnt1=0\n",
    "'''\n",
    "cnt0 and cnt1 are variables that keep track of the number of cases where no rule applies for each class. In the code, they are initialized to 0 before the for-loops, and then updated within the loops based on whether or not a rule applies to a given transaction. If no rule applies, the corresponding count is incremented.\n",
    "'''\n",
    "\n",
    "for i in range(y_0.shape[0]):\n",
    "    maxp=-1\n",
    "    '''\n",
    "     maxp is a variable that stores the maximum confidence value for a rule that satisfies certain conditions. In the first for loop, maxp is the maximum confidence value among rules that belong to class 0 and contain all the items in the current transaction. In the second for loop, maxp is the maximum confidence value among rules that belong to class 1 and contain all the items in the current transaction. If no rule satisfies the conditions, maxp remains -1.\n",
    "    '''\n",
    "    for j in range(y_0.shape[1]):\n",
    "        if (c_per_rule[j]==0 and y_0[i,j]>=item_len[j]):\n",
    "            maxp = max(maxp, conf[j])\n",
    "    if (maxp==-1):\n",
    "        cnt0 = cnt0+1\n",
    "    else:\n",
    "        pred[i,0] = maxp\n",
    "\n",
    "    maxp=-1\n",
    "    for j in range(y_0.shape[1]):\n",
    "        if (c_per_rule[j]==1 and y_0[i,j]>=item_len[j]):\n",
    "            maxp = max(maxp, conf[j])\n",
    "\n",
    "    if (maxp==-1):\n",
    "        cnt1 = cnt1+1\n",
    "    else:\n",
    "        pred[i,1] = maxp\n",
    "print(y_0.shape[0],cnt0, cnt1)\n",
    "\n",
    "cnt0=0\n",
    "cnt1=0\n",
    "for i in range(y_1.shape[0]):\n",
    "    maxp=-1\n",
    "    for j in range(y_1.shape[1]):\n",
    "        if (c_per_rule[j]==0 and y_1[i,j]>=item_len[j]):\n",
    "            maxp = max(maxp, conf[j])\n",
    "    if (maxp==-1):\n",
    "        cnt0 = cnt0+1\n",
    "    else:\n",
    "        pred[i+y_0.shape[0],0] = maxp\n",
    "\n",
    "    maxp=-1\n",
    "    for j in range(y_1.shape[1]):\n",
    "        if (c_per_rule[j]==1 and y_1[i,j]>=item_len[j]):\n",
    "            maxp = max(maxp, conf[j])\n",
    "\n",
    "    if (maxp==-1):\n",
    "        cnt1 = cnt1+1\n",
    "    else:\n",
    "        pred[i+y_0.shape[0],1] = maxp\n",
    "\n",
    "print(y_1.shape[0],cnt0, cnt1)\n",
    "\n",
    "y = np.concatenate((np.zeros(te_0_ary.shape[0]), np.ones(te_1_ary.shape[0])), axis=0)\n",
    "auc = roc_auc_score(y,pred[:,1])\n",
    "print(auc)\n",
    "y = np.concatenate((np.zeros(te_0_ary.shape[0]), np.ones(te_1_ary.shape[0])), axis=0)\n",
    "auc = roc_auc_score(y,-pred[:,0])\n",
    "print(auc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3762 0 23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#first rule used for training data\n",
    "y_00 = np.matmul(tr_0_ary, cp_attr_contained_freq_items)\n",
    "y_01 = np.matmul(tr_1_ary, cp_attr_contained_freq_items)\n",
    "# Each element in the matrix indicates the count of how many times the corresponding frequent itemset occurred in the transactions of the corresponding class.\n",
    "\n",
    "\n",
    "pred0 = np.zeros(y_00.shape[0]+y_01.shape[0])\n",
    "cnt0=0\n",
    "cnt1=0\n",
    "for i in range(y_00.shape[0]):\n",
    "    maxp=-1\n",
    "    for j in range(y_00.shape[1]):\n",
    "        if (c_per_rule[j]==1 and y_00[i,j]>=item_len[j]):\n",
    "            maxp = max(maxp, conf[j])\n",
    "\n",
    "    if (maxp==-1):\n",
    "        cnt1 = cnt1+1\n",
    "    else:\n",
    "        pred0[i] = maxp\n",
    "print(y_00.shape[0],cnt0, cnt1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393 0 0\n"
     ]
    }
   ],
   "source": [
    "cnt0=0\n",
    "cnt1=0\n",
    "for i in range(y_01.shape[0]):\n",
    "\n",
    "    maxp=-1\n",
    "    for j in range(y_01.shape[1]):\n",
    "        if (c_per_rule[j]==1 and y_01[i,j]>=item_len[j]):\n",
    "            maxp = max(maxp, conf[j])\n",
    "\n",
    "    if (maxp==-1):\n",
    "        cnt1 = cnt1+1\n",
    "    else:\n",
    "        pred0[i+y_00.shape[0]] = maxp\n",
    "\n",
    "print(y_01.shape[0],cnt0, cnt1)\n",
    "\n",
    "y0 = np.concatenate((np.zeros(tr_0_ary.shape[0]), np.ones(tr_1_ary.shape[0])), axis=0)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4654088050314466\n",
      "TP: 37 FN: 6\n",
      "FP: 79 TN: 338\n",
      "pre: 0.31896551724137934 rec: 0.8604651162790697\n",
      "f1: 0.46540880503144655\n"
     ]
    }
   ],
   "source": [
    "z_1 = pred0[y0==1]\n",
    "m = np.mean(z_1)\n",
    "s = np.std(z_1)\n",
    "th = m\n",
    "\n",
    "pred_y = np.zeros(pred.shape[0], dtype=int)\n",
    "for i in range(pred.shape[0]):\n",
    "    if (pred[i,1]>=th):\n",
    "        pred_y[i]=1\n",
    "\n",
    "print(f1_score(y,pred_y))\n",
    "\n",
    "TP=0\n",
    "FP=0\n",
    "FN=0\n",
    "TN=0\n",
    "for i in range(pred.shape[0]):\n",
    "    if (y[i]==1 and pred_y[i]==1):\n",
    "        TP = TP+1\n",
    "    elif (y[i]==1 and pred_y[i]==0):\n",
    "        FN = FN+1\n",
    "    elif (y[i]==0 and pred_y[i]==1):\n",
    "        FP = FP+1\n",
    "    else:\n",
    "        TN = TN+1\n",
    "\n",
    "print('TP:', TP, 'FN:', FN)\n",
    "print('FP:', FP, 'TN:', TN)\n",
    "print('pre:', TP/(TP+FP), 'rec:', TP/(TP+FN))\n",
    "print('f1:', (2*TP)/(2*TP + FP + FN))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
