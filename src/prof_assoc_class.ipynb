{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# class 0에서 랜덤하게 1100개를 선택해서 사용\n",
    "import csv\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import random\n",
    "from mlxtend.frequent_patterns import apriori"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4615\n"
     ]
    }
   ],
   "source": [
    "with open('../data/dataset.csv', 'r') as file:\n",
    "        data_set = [list(filter(None, row)) for row in csv.reader(file)]\n",
    "\n",
    "print(len(data_set))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4615, 149)\n"
     ]
    }
   ],
   "source": [
    "te = TransactionEncoder()\n",
    "te_ary = te.fit_transform(data_set)\n",
    "m_transactions = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "print(m_transactions.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "transactions_0 = pd.DataFrame(\n",
    "            m_transactions[m_transactions['0']].reset_index(drop=True).drop(['1', '0'], axis=1))\n",
    "transactions_1 = pd.DataFrame(\n",
    "            m_transactions[m_transactions['1']].reset_index(drop=True).drop(['1', '0'], axis=1))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# seeds [0, 10, 35, 42, 123, 456, 789, 101112, 131415, 161718]\n",
    "random.seed(0)\n",
    "indices = list( range(0, len(transactions_0)) )\n",
    "random.shuffle(indices)\n",
    "transactions_te_0 = transactions_0.iloc[indices[:417],:]\n",
    "#transactions_tr_00 = transactions_0.iloc[indices[417:810],:]\n",
    "transactions_tr_0 = transactions_0.iloc[indices[417:],:]\n",
    "\n",
    "indices = list( range(0, len(transactions_1)) )\n",
    "random.shuffle(indices)\n",
    "transactions_te_1 = transactions_1.iloc[indices[:43],:]\n",
    "transactions_tr_1 = transactions_1.iloc[indices[43:],:]\n",
    "\n",
    "tr_0_ary=(transactions_tr_0.values).astype('int')\n",
    "tr_1_ary=(transactions_tr_1.values).astype('int')\n",
    "\n",
    "#tr_00_ary=(transactions_tr_00.values).astype('int')\n",
    "\n",
    "transactions_tr = pd.concat([transactions_tr_0, transactions_tr_1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "      ACETAMINOPHEN  ALBUMIN HUMAN 25%  ALBUMIN HUMAN 5%  ALBUTEROL 0.083%  \\\n856           False              False             False             False   \n2242           True              False             False             False   \n622            True              False             False             False   \n3873           True              False             False             False   \n360            True              False             False             False   \n...             ...                ...               ...               ...   \n203            True              False             False             False   \n90             True              False             False             False   \n128           False              False             False             False   \n78             True              False             False             False   \n50             True              False             False             False   \n\n      ALBUTEROL 90 MCG  ALBUTEROL CONCENTRATED 0.5%  ALLOPURINOL  ALPRAZOLAM  \\\n856              False                        False        False       False   \n2242             False                        False        False       False   \n622               True                         True        False       False   \n3873             False                        False        False       False   \n360               True                         True        False       False   \n...                ...                          ...          ...         ...   \n203               True                         True        False       False   \n90                True                         True        False       False   \n128              False                        False        False       False   \n78               False                        False        False       False   \n50               False                        False        False       False   \n\n      AMINOCAPROIC ACID  AMIODARONE  ...  TACROLIMUS  TAMSULOSIN  THIAMINE  \\\n856               False       False  ...       False       False      True   \n2242              False       False  ...       False       False      True   \n622               False       False  ...       False        True     False   \n3873              False       False  ...       False       False     False   \n360               False       False  ...       False       False     False   \n...                 ...         ...  ...         ...         ...       ...   \n203               False       False  ...       False       False     False   \n90                False       False  ...       False       False     False   \n128               False       False  ...       False       False     False   \n78                False       False  ...       False       False     False   \n50                False       False  ...       False       False     False   \n\n      TRAMADOL  TRAZODONE  VANCOMYCIN  VANCOMYCIN 1 G/200 ML D5W  \\\n856      False      False        True                       True   \n2242     False      False       False                      False   \n622      False      False       False                       True   \n3873     False      False       False                      False   \n360      False      False       False                      False   \n...        ...        ...         ...                        ...   \n203      False      False        True                      False   \n90       False      False       False                       True   \n128      False      False       False                       True   \n78       False      False       False                      False   \n50       False      False       False                      False   \n\n      VANCOMYCIN 1.25 G/250 ML NS  VANCOMYCIN 1.5 G/500 ML NS  WARFARIN  \n856                          True                       False     False  \n2242                        False                       False     False  \n622                          True                       False     False  \n3873                        False                       False     False  \n360                         False                       False     False  \n...                           ...                         ...       ...  \n203                         False                       False     False  \n90                           True                       False     False  \n128                         False                       False     False  \n78                          False                       False     False  \n50                          False                       False     False  \n\n[4155 rows x 147 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ACETAMINOPHEN</th>\n      <th>ALBUMIN HUMAN 25%</th>\n      <th>ALBUMIN HUMAN 5%</th>\n      <th>ALBUTEROL 0.083%</th>\n      <th>ALBUTEROL 90 MCG</th>\n      <th>ALBUTEROL CONCENTRATED 0.5%</th>\n      <th>ALLOPURINOL</th>\n      <th>ALPRAZOLAM</th>\n      <th>AMINOCAPROIC ACID</th>\n      <th>AMIODARONE</th>\n      <th>...</th>\n      <th>TACROLIMUS</th>\n      <th>TAMSULOSIN</th>\n      <th>THIAMINE</th>\n      <th>TRAMADOL</th>\n      <th>TRAZODONE</th>\n      <th>VANCOMYCIN</th>\n      <th>VANCOMYCIN 1 G/200 ML D5W</th>\n      <th>VANCOMYCIN 1.25 G/250 ML NS</th>\n      <th>VANCOMYCIN 1.5 G/500 ML NS</th>\n      <th>WARFARIN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>856</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2242</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>622</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3873</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>360</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>203</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>128</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>4155 rows × 147 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_tr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "460"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([transactions_te_0, transactions_te_1]).shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4155, 147) 23105\n"
     ]
    }
   ],
   "source": [
    "frequent_items = apriori(transactions_tr, min_support=0.1)\n",
    "print(transactions_tr.shape, len(frequent_items))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "attributes_count = transactions_tr.shape[1]  #number of attributes\n",
    "freq_itemsets_count = len(frequent_items)   #number of frequent items\n",
    "freq_itemsets = frequent_items['itemsets']\n",
    "freq_itemsets_matrix = [list(x) for x in freq_itemsets]\n",
    "attributes_contained_in_freq_items= np.zeros((attributes_count, freq_itemsets_count))\n",
    "for i in range(len(frequent_items)):\n",
    "    attributes_contained_in_freq_items[freq_itemsets_matrix[i],i]=1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class rules 22205\n"
     ]
    }
   ],
   "source": [
    "#lift\n",
    "cp_attr_contained_freq_items = copy.deepcopy(attributes_contained_in_freq_items)\n",
    "freq_count_per_trans_0 = np.matmul(tr_0_ary, attributes_contained_in_freq_items)\n",
    "freq_count_per_trans_1 = np.matmul(tr_1_ary, attributes_contained_in_freq_items)\n",
    "# Each element in the matrix indicates the count of how many times the corresponding frequent itemset occurred in the transactions of the corresponding class.\n",
    "\n",
    "item_len = np.sum(attributes_contained_in_freq_items, axis=0) #item length\n",
    "cls0 = np.zeros(freq_itemsets_count)   #frequent_items['support']\n",
    "cls1 = np.zeros(freq_itemsets_count)\n",
    "p = np.zeros(freq_itemsets_count)\n",
    "conf = np.zeros(freq_itemsets_count)\n",
    "c_per_rule = np.zeros(freq_itemsets_count, dtype=int)\n",
    "cnt=0\n",
    "for i in range(freq_count_per_trans_0.shape[1]):\n",
    "    cls0[i] = (freq_count_per_trans_0[:, i] >= item_len[i]).sum() / freq_count_per_trans_0.shape[0]\n",
    "    cls1[i] = (freq_count_per_trans_1[:, i] >= item_len[i]).sum() / freq_count_per_trans_1.shape[0]\n",
    "    p[i] = ((freq_count_per_trans_0[:, i] >= item_len[i]).sum() + (freq_count_per_trans_1[:, i] >= item_len[i]).sum()) / (freq_count_per_trans_0.shape[0] + freq_count_per_trans_1.shape[0])\n",
    "\n",
    "    '''\n",
    "    p: proportion of transactions in which the corresponding frequent itemset appears\n",
    "    it is calculated as the sum of the number of transactions containing the itemset\n",
    "    in both classes (0 and 1) divided by the total number of transactions.\n",
    "\n",
    "    cls0[i]/p[i] is the ratio of the number of transactions in which the itemset appears in class 0 to the total number of transactions in which the itemset appears, regardless of the class. The confidence score indicates the likelihood that the rule's consequent will be present in transactions that contain its antecedent.\n",
    "\n",
    "    The line elif cls0[i]/p[i]<1 and cls1[i]/p[i]>1: is checking whether the confidence of the association rule in question is greater for class 1 than class 0, and whether that confidence is greater than 1.\n",
    "    If the confidence of the rule is less for class 0 than class 1, but the confidence for class 1 is greater than 1, then the rule is said to have a \"class 1\" association, meaning that it is more strongly associated with class 1. In this case, indc[i] is set to 1, indicating that the rule has a class 1 association, and conf[i] is set to the ratio of the support of the rule in class 1 to the overall support of the rule in both classes.\n",
    "    '''\n",
    "\n",
    "    if cls0[i]/p[i]>1:\n",
    "        c_per_rule[i] = 0\n",
    "        conf[i] = cls0[i]/p[i]\n",
    "        cnt = cnt +1\n",
    "    elif cls0[i]/p[i]<1 and cls1[i]/p[i]>1:\n",
    "        c_per_rule[i] = 1\n",
    "        conf[i] = cls1[i]/p[i]\n",
    "        cnt = cnt +1\n",
    "    else:\n",
    "        conf[i]=0\n",
    "        cp_attr_contained_freq_items[:, i]=0\n",
    "        c_per_rule[i] =-1\n",
    "print('class rules', cnt)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rules for class 0: 14704 Rules for class 1: 7501\n",
      "Avg conf for class 0: 1.0494745383338224, Avg conf for class 1: 1.5226197565933932\n",
      "417 5 3\n",
      "43 0 0\n",
      "0.9008142323350622\n",
      "0.7713735987953823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(f\"Rules for class 0: {(c_per_rule == 0).sum()} Rules for class 1: {(c_per_rule == 1).sum()}\")\n",
    "print(f\"Avg conf for class 0: {conf[c_per_rule == 0].mean()}, Avg conf for class 1: {conf[c_per_rule == 1].mean()}\")\n",
    "\n",
    "te_0_ary=(transactions_te_0.values).astype('int')\n",
    "te_1_ary=(transactions_te_1.values).astype('int')\n",
    "\n",
    "#first rule used\n",
    "y_0 = np.matmul(te_0_ary, cp_attr_contained_freq_items)\n",
    "y_1 = np.matmul(te_1_ary, cp_attr_contained_freq_items)\n",
    "# Each element in the matrix indicates the count of how many times the corresponding frequent itemset occurred in the transactions of the corresponding class.\n",
    "\n",
    "pred = np.zeros((y_0.shape[0]+y_1.shape[0],2))\n",
    "cnt0=0\n",
    "cnt1=0\n",
    "'''\n",
    "cnt0 and cnt1 are variables that keep track of the number of cases where no rule applies for each class. In the code, they are initialized to 0 before the for-loops, and then updated within the loops based on whether or not a rule applies to a given transaction. If no rule applies, the corresponding count is incremented.\n",
    "'''\n",
    "\n",
    "for i in range(y_0.shape[0]):\n",
    "    maxp=-1\n",
    "    '''\n",
    "     maxp is a variable that stores the maximum confidence value for a rule that satisfies certain conditions. In the first for loop, maxp is the maximum confidence value among rules that belong to class 0 and contain all the items in the current transaction. In the second for loop, maxp is the maximum confidence value among rules that belong to class 1 and contain all the items in the current transaction. If no rule satisfies the conditions, maxp remains -1.\n",
    "    '''\n",
    "    for j in range(y_0.shape[1]):\n",
    "        if (c_per_rule[j]==0 and y_0[i,j]>=item_len[j]):\n",
    "            maxp = max(maxp, conf[j])\n",
    "    if (maxp==-1):\n",
    "        cnt0 = cnt0+1\n",
    "    else:\n",
    "        pred[i,0] = maxp\n",
    "\n",
    "    maxp=-1\n",
    "    for j in range(y_0.shape[1]):\n",
    "        if (c_per_rule[j]==1 and y_0[i,j]>=item_len[j]):\n",
    "            maxp = max(maxp, conf[j])\n",
    "\n",
    "    if (maxp==-1):\n",
    "        cnt1 = cnt1+1\n",
    "    else:\n",
    "        pred[i,1] = maxp\n",
    "print(y_0.shape[0],cnt0, cnt1)\n",
    "\n",
    "cnt0=0\n",
    "cnt1=0\n",
    "for i in range(y_1.shape[0]):\n",
    "    maxp=-1\n",
    "    for j in range(y_1.shape[1]):\n",
    "        if (c_per_rule[j]==0 and y_1[i,j]>=item_len[j]):\n",
    "            maxp = max(maxp, conf[j])\n",
    "    if (maxp==-1):\n",
    "        cnt0 = cnt0+1\n",
    "    else:\n",
    "        pred[i+y_0.shape[0],0] = maxp\n",
    "\n",
    "    maxp=-1\n",
    "    for j in range(y_1.shape[1]):\n",
    "        if (c_per_rule[j]==1 and y_1[i,j]>=item_len[j]):\n",
    "            maxp = max(maxp, conf[j])\n",
    "\n",
    "    if (maxp==-1):\n",
    "        cnt1 = cnt1+1\n",
    "    else:\n",
    "        pred[i+y_0.shape[0],1] = maxp\n",
    "\n",
    "print(y_1.shape[0],cnt0, cnt1)\n",
    "\n",
    "y = np.concatenate((np.zeros(te_0_ary.shape[0]), np.ones(te_1_ary.shape[0])), axis=0)\n",
    "auc = roc_auc_score(y,pred[:,1])\n",
    "print(auc)\n",
    "y = np.concatenate((np.zeros(te_0_ary.shape[0]), np.ones(te_1_ary.shape[0])), axis=0)\n",
    "auc = roc_auc_score(y,-pred[:,0])\n",
    "print(auc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3762 0 23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#first rule used for training data\n",
    "y_00 = np.matmul(tr_0_ary, cp_attr_contained_freq_items)\n",
    "y_01 = np.matmul(tr_1_ary, cp_attr_contained_freq_items)\n",
    "# Each element in the matrix indicates the count of how many times the corresponding frequent itemset occurred in the transactions of the corresponding class.\n",
    "\n",
    "\n",
    "pred0 = np.zeros(y_00.shape[0]+y_01.shape[0])\n",
    "cnt0=0\n",
    "cnt1=0\n",
    "for i in range(y_00.shape[0]):\n",
    "    maxp=-1\n",
    "    for j in range(y_00.shape[1]):\n",
    "        if (c_per_rule[j]==1 and y_00[i,j]>=item_len[j]):\n",
    "            maxp = max(maxp, conf[j])\n",
    "\n",
    "    if (maxp==-1):\n",
    "        cnt1 = cnt1+1\n",
    "    else:\n",
    "        pred0[i] = maxp\n",
    "print(y_00.shape[0],cnt0, cnt1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393 0 0\n"
     ]
    }
   ],
   "source": [
    "cnt0=0\n",
    "cnt1=0\n",
    "for i in range(y_01.shape[0]):\n",
    "\n",
    "    maxp=-1\n",
    "    for j in range(y_01.shape[1]):\n",
    "        if (c_per_rule[j]==1 and y_01[i,j]>=item_len[j]):\n",
    "            maxp = max(maxp, conf[j])\n",
    "\n",
    "    if (maxp==-1):\n",
    "        cnt1 = cnt1+1\n",
    "    else:\n",
    "        pred0[i+y_00.shape[0]] = maxp\n",
    "\n",
    "print(y_01.shape[0],cnt0, cnt1)\n",
    "\n",
    "y0 = np.concatenate((np.zeros(tr_0_ary.shape[0]), np.ones(tr_1_ary.shape[0])), axis=0)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4654088050314466\n",
      "TP: 37 FN: 6\n",
      "FP: 79 TN: 338\n",
      "pre: 0.31896551724137934 rec: 0.8604651162790697\n",
      "f1: 0.46540880503144655\n"
     ]
    }
   ],
   "source": [
    "z_1 = pred0[y0==1]\n",
    "m = np.mean(z_1)\n",
    "s = np.std(z_1)\n",
    "th = m\n",
    "\n",
    "pred_y = np.zeros(pred.shape[0], dtype=int)\n",
    "for i in range(pred.shape[0]):\n",
    "    if (pred[i,1]>=th):\n",
    "        pred_y[i]=1\n",
    "\n",
    "print(f1_score(y,pred_y))\n",
    "\n",
    "TP=0\n",
    "FP=0\n",
    "FN=0\n",
    "TN=0\n",
    "for i in range(pred.shape[0]):\n",
    "    if (y[i]==1 and pred_y[i]==1):\n",
    "        TP = TP+1\n",
    "    elif (y[i]==1 and pred_y[i]==0):\n",
    "        FN = FN+1\n",
    "    elif (y[i]==0 and pred_y[i]==1):\n",
    "        FP = FP+1\n",
    "    else:\n",
    "        TN = TN+1\n",
    "\n",
    "print('TP:', TP, 'FN:', FN)\n",
    "print('FP:', FP, 'TN:', TN)\n",
    "print('pre:', TP/(TP+FP), 'rec:', TP/(TP+FN))\n",
    "print('f1:', (2*TP)/(2*TP + FP + FN))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.08313483, 1.97438609],\n       [1.07891252, 2.06415849],\n       [1.06734081, 3.05262875],\n       [1.08981276, 3.67827185],\n       [1.08859043, 1.57315382],\n       [1.09453793, 2.03414263],\n       [1.09453793, 1.96480443],\n       [1.09925597, 1.7420628 ],\n       [1.09925597, 2.11911058],\n       [0.        , 2.1440773 ],\n       [1.09119088, 2.66806496],\n       [1.0812138 , 2.12415909],\n       [1.09449311, 3.86919696],\n       [1.09925597, 3.17175573],\n       [1.0874365 , 3.86919696],\n       [1.08614519, 1.64194425],\n       [1.09672413, 3.86919696],\n       [1.09045557, 1.82948873],\n       [1.07067708, 3.20315925],\n       [1.08882172, 3.99010937],\n       [1.09449311, 1.65282176],\n       [1.08937051, 2.43288081],\n       [1.09119088, 3.38320611],\n       [1.09659541, 3.07235597],\n       [1.07733143, 1.26949572],\n       [1.09453793, 1.79905336],\n       [1.09703657, 3.86919696],\n       [1.08106601, 1.85868483],\n       [1.08466453, 1.58373768],\n       [1.09396366, 3.38320611],\n       [1.09688357, 2.2270273 ],\n       [1.09461906, 2.66806496],\n       [1.09925597, 1.98460256],\n       [1.09205598, 3.99010937],\n       [1.08937051, 3.86919696],\n       [1.08693451, 3.86919696],\n       [1.09688357, 3.75862945],\n       [1.07067708, 2.28143833],\n       [1.08632667, 1.6442212 ],\n       [1.0874365 , 2.56902333],\n       [1.09672413, 3.86919696],\n       [1.08068535, 3.10593459],\n       [1.07163658, 3.86919696],\n       [1.07413713, 2.02052587],\n       [1.08422092, 1.85868483],\n       [1.09925597, 3.99010937],\n       [1.03768406, 1.96781235],\n       [1.07920766, 1.02443788],\n       [1.08345051, 3.02928916],\n       [1.07562406, 3.86919696],\n       [1.09449311, 3.86919696],\n       [1.09688357, 2.20993273],\n       [1.0917707 , 2.2270273 ],\n       [1.08916133, 2.15970699],\n       [1.09672413, 3.17902206],\n       [1.09119088, 2.09335878],\n       [1.03952675, 1.39762617],\n       [1.07217139, 2.11911058],\n       [1.09453793, 2.03917137],\n       [1.08107702, 3.26432617],\n       [1.04508583, 2.15072658],\n       [1.09243449, 2.19429641],\n       [1.07819869, 1.61667161],\n       [1.09449311, 3.86919696],\n       [1.09703657, 3.99010937],\n       [1.07729904, 2.09335878],\n       [1.08709209, 2.51726645],\n       [1.07562848, 1.78720791],\n       [1.08257102, 1.49777354],\n       [1.09672413, 2.35726715],\n       [1.09688357, 2.11911058],\n       [1.0874365 , 2.03992588],\n       [1.09423918, 3.07235597],\n       [1.08332761, 2.03864718],\n       [1.09688357, 3.99010937],\n       [1.05065841, 1.39762617],\n       [1.09688357, 3.86919696],\n       [1.09706973, 1.36347498],\n       [1.07793619, 2.28909588],\n       [1.08937051, 2.56902333],\n       [1.0917707 , 2.16918926],\n       [1.08420028, 2.19429641],\n       [1.08106601, 2.02052587],\n       [1.09033608, 2.06415849],\n       [1.08429282, 3.78035064],\n       [1.09205598, 1.97438609],\n       [1.07920766, 3.26432617],\n       [1.08990133, 2.16206934],\n       [0.        , 1.65282176],\n       [1.02298873, 3.38320611],\n       [1.09703657, 2.90619008],\n       [1.08166711, 3.75862945],\n       [1.09691811, 3.86919696],\n       [1.08882172, 1.7744088 ],\n       [1.0749477 , 3.86919696],\n       [1.08590326, 1.83697519],\n       [1.09706973, 2.08892514],\n       [1.08245643, 2.19429641],\n       [1.08429282, 1.39327771],\n       [1.09925597, 2.56902333],\n       [1.08601402, 2.66806496],\n       [1.08614519, 3.26432617],\n       [1.07068205, 3.99010937],\n       [1.09453793, 1.66196796],\n       [1.07357156, 1.85258643],\n       [1.07217139, 1.02141764],\n       [1.09119088, 2.66806496],\n       [1.09925597, 2.09335878],\n       [1.09925597, 3.20315925],\n       [1.08245643, 2.2270273 ],\n       [1.09449311, 3.99010937],\n       [1.08280952, 3.86919696],\n       [1.08420028, 3.17175573],\n       [1.09205598, 2.49659075],\n       [1.08429282, 2.66806496],\n       [1.09216654, 1.7744088 ],\n       [1.09119088, 3.86919696],\n       [1.02562344, 3.86919696],\n       [1.08981276, 1.74983278],\n       [1.09243449, 3.99010937],\n       [1.09246065, 1.29969502],\n       [1.09925597, 3.20315925],\n       [1.09925597, 3.86919696],\n       [1.08529928, 3.26432617],\n       [1.08062832, 3.10367511],\n       [1.08106601, 1.02443788],\n       [1.08429282, 2.09335878],\n       [1.07067708, 1.15926744],\n       [1.09688357, 3.53126392],\n       [1.07729904, 3.67827185],\n       [1.08405464, 1.51927932],\n       [1.09703657, 3.20315925],\n       [1.09243449, 3.03501336],\n       [1.08776301, 2.11911058],\n       [1.09119088, 2.06415849],\n       [1.09703657, 3.86919696],\n       [1.086002  , 2.17243543],\n       [1.08937051, 3.86919696],\n       [1.07889937, 1.96448834],\n       [1.07847828, 2.16918926],\n       [1.08882172, 2.2270273 ],\n       [1.02680796, 0.        ],\n       [1.07413713, 1.05952557],\n       [1.08106601, 3.20106122],\n       [1.08280952, 2.12415909],\n       [1.09453793, 2.09335878],\n       [1.09453793, 3.10956444],\n       [1.09453793, 2.10018438],\n       [1.09925597, 3.86919696],\n       [1.09453793, 2.11911058],\n       [1.09396366, 1.84040147],\n       [1.03952675, 2.06253444],\n       [1.09925597, 3.86919696],\n       [1.00317812, 1.33973579],\n       [1.09688357, 3.38320611],\n       [1.09423918, 2.15815183],\n       [1.07357156, 2.56902333],\n       [1.09449311, 1.89547155],\n       [0.        , 0.        ],\n       [1.08222815, 2.11911058],\n       [1.08882172, 2.2270273 ],\n       [1.08332761, 2.60692251],\n       [1.06403248, 3.99010937],\n       [1.08859043, 2.06415849],\n       [1.08280952, 1.57315382],\n       [1.09453793, 1.35604049],\n       [1.09562998, 2.60692251],\n       [1.08681443, 1.81192923],\n       [1.08937051, 2.12415909],\n       [1.08930142, 3.86919696],\n       [1.09688357, 2.28143833],\n       [1.09119088, 1.81535394],\n       [1.09703657, 3.26432617],\n       [1.09706973, 3.86919696],\n       [1.08352797, 2.11911058],\n       [1.07891252, 1.84866302],\n       [1.09453793, 3.99010937],\n       [1.08405464, 1.6815851 ],\n       [1.09925597, 3.0446937 ],\n       [1.09691811, 2.56902333],\n       [1.060699  , 1.82948873],\n       [1.09925597, 3.86919696],\n       [1.09925597, 2.89853332],\n       [1.07962088, 0.        ],\n       [1.09423918, 3.86919696],\n       [1.06734081, 3.53126392],\n       [1.05219676, 3.53126392],\n       [1.09688357, 2.2655398 ],\n       [1.08981276, 3.17902206],\n       [1.09925597, 3.86919696],\n       [1.09925597, 2.90619008],\n       [1.09672413, 3.99010937],\n       [1.09453793, 3.20106122],\n       [1.08171928, 1.7744088 ],\n       [1.08377314, 1.50054171],\n       [1.09461906, 1.1205063 ],\n       [1.06598258, 1.50054171],\n       [1.08681443, 1.78211022],\n       [1.09925597, 3.86919696],\n       [1.07685407, 1.56289413],\n       [1.08465467, 1.91812441],\n       [1.08106601, 1.89515026],\n       [1.09925597, 3.86919696],\n       [1.08524475, 2.12415909],\n       [1.09562998, 2.74249555],\n       [1.08937051, 3.17175573],\n       [1.09205598, 3.20641972],\n       [1.09925597, 3.86919696],\n       [1.08145601, 3.26432617],\n       [1.07891252, 3.86919696],\n       [1.09925597, 3.53126392],\n       [1.09688357, 2.46179239],\n       [1.07936422, 1.05952557],\n       [1.08859043, 1.54932684],\n       [1.08429282, 3.26432617],\n       [1.09205598, 2.52298751],\n       [1.09449311, 3.10956444],\n       [1.08981276, 3.38320611],\n       [1.09925597, 2.74249555],\n       [1.09925597, 2.74249555],\n       [1.09036615, 3.99010937],\n       [1.08930142, 1.78828854],\n       [1.09925597, 2.74249555],\n       [1.09243449, 3.86919696],\n       [1.09205598, 3.38320611],\n       [1.08808592, 1.82369793],\n       [1.0917707 , 3.99010937],\n       [1.09672413, 3.99010937],\n       [1.07413713, 3.86919696],\n       [1.09925597, 2.90619008],\n       [1.09925597, 3.20315925],\n       [1.09453793, 3.07235597],\n       [1.08681443, 2.56902333],\n       [1.09453793, 2.06053736],\n       [1.09453793, 1.96441378],\n       [1.0917707 , 1.78720791],\n       [1.09119088, 3.86919696],\n       [1.09045557, 2.09335878],\n       [1.08585112, 1.44608924],\n       [1.08614519, 1.98460256],\n       [1.08280952, 1.38349498],\n       [1.08352797, 1.60369671],\n       [1.09925597, 3.99010937],\n       [1.09925597, 2.13105571],\n       [1.09562998, 2.50460096],\n       [1.09520394, 2.40500997],\n       [1.08937051, 1.97438609],\n       [1.09703657, 3.99010937],\n       [1.09925597, 3.20315925],\n       [0.        , 1.24832153],\n       [1.09243449, 2.19429641],\n       [1.08534076, 1.51035987],\n       [1.09925597, 2.74249555],\n       [1.08538207, 1.84866302],\n       [1.09672413, 3.86853089],\n       [1.08166711, 2.04241846],\n       [1.09520394, 1.87421929],\n       [1.08280952, 2.09335878],\n       [1.09925597, 2.74249555],\n       [1.09925597, 3.17902206],\n       [1.07213425, 2.89853332],\n       [1.07320725, 2.97213474],\n       [1.09925597, 2.74249555],\n       [1.09925597, 2.90619008],\n       [1.08521576, 1.33973579],\n       [1.08352797, 3.99010937],\n       [1.09562998, 1.60369671],\n       [1.08409348, 1.72578362],\n       [1.09688357, 3.86853089],\n       [1.09205598, 2.40500997],\n       [1.09688357, 2.28143833],\n       [1.09453793, 2.16430191],\n       [1.09449311, 3.86919696],\n       [1.09453793, 3.05262875],\n       [1.08202735, 1.9372007 ],\n       [1.0745531 , 3.03346539],\n       [1.08981276, 1.59111178],\n       [1.08937051, 2.02052587],\n       [1.09119088, 2.40500997],\n       [1.06487423, 3.05262875],\n       [1.09706973, 2.2655398 ],\n       [1.08981276, 2.03917137],\n       [0.        , 1.26949572],\n       [1.09243449, 2.06610848],\n       [1.07842422, 3.38320611],\n       [1.08106601, 1.68573961],\n       [1.08107702, 3.17175573],\n       [1.09449311, 3.86919696],\n       [1.08433877, 3.17902206],\n       [1.09688357, 1.90686717],\n       [1.08652775, 1.39327771],\n       [1.08280952, 2.35726715],\n       [1.09925597, 3.20315925],\n       [1.09688357, 3.99010937],\n       [1.07936422, 1.82616239],\n       [1.09246065, 2.35726715],\n       [1.07357156, 3.53126392],\n       [1.08747393, 1.80891938],\n       [1.06400909, 2.36037635],\n       [1.0874365 , 2.60692251],\n       [1.09205598, 1.96441378],\n       [1.06492636, 1.42606071],\n       [1.07920766, 3.26432617],\n       [1.09688357, 3.86853089],\n       [1.0917707 , 2.56902333],\n       [1.09251262, 1.43169529],\n       [1.08957404, 2.35726715],\n       [1.08548864, 1.62244947],\n       [1.09453793, 2.20993273],\n       [1.09703657, 3.86919696],\n       [1.07001844, 3.05262875],\n       [1.09479861, 1.90686717],\n       [1.08588591, 1.7744088 ],\n       [1.04591953, 2.18604718],\n       [1.09925597, 2.60692251],\n       [1.08937051, 2.12415909],\n       [1.06870963, 3.26432617],\n       [1.08981276, 1.29969502],\n       [1.07320725, 3.26432617],\n       [1.0824644 , 2.12415909],\n       [1.09691811, 3.86919696],\n       [1.09205598, 3.86919696],\n       [1.09243449, 3.86919696],\n       [1.08345051, 2.86117468],\n       [1.07406757, 1.45309504],\n       [1.09925597, 1.54654756],\n       [1.08107702, 1.60369671],\n       [1.08859043, 1.42933198],\n       [1.09423918, 2.60692251],\n       [1.09706973, 1.84040147],\n       [1.04680284, 2.17599945],\n       [1.08347824, 3.38320611],\n       [1.09925597, 3.17902206],\n       [1.0745531 , 1.65412498],\n       [1.09453793, 1.39453473],\n       [1.08222815, 1.48243334],\n       [1.08534076, 1.26949572],\n       [1.08937051, 1.71080344],\n       [1.0816147 , 2.04241846],\n       [1.08466453, 3.38320611],\n       [1.09423918, 3.86853089],\n       [1.04591953, 1.56289413],\n       [1.08859043, 2.09335878],\n       [1.08429282, 3.17175573],\n       [1.0874365 , 2.13105571],\n       [1.09001476, 1.49671204],\n       [1.09205598, 2.2270273 ],\n       [1.09453793, 1.24832153],\n       [1.0749477 , 1.39327771],\n       [1.09688357, 3.86919696],\n       [1.08429282, 2.03414263],\n       [1.09688357, 2.18127762],\n       [1.09246065, 2.16918926],\n       [1.09706973, 2.17243543],\n       [1.07793619, 2.15970699],\n       [1.08338812, 3.13634537],\n       [1.09119088, 2.56902333],\n       [1.09706973, 1.7744088 ],\n       [1.09423918, 2.03031982],\n       [1.09449311, 3.86919696],\n       [1.09925597, 3.75862945],\n       [1.08250814, 1.85372549],\n       [1.09205598, 3.17175573],\n       [1.08107702, 1.20690857],\n       [1.08708775, 2.20993273],\n       [1.0749477 , 2.11911058],\n       [1.0749477 , 3.99010937],\n       [1.0917707 , 2.12415909],\n       [1.0749477 , 1.18050459],\n       [1.0824644 , 1.30488314],\n       [1.0917707 , 2.19429641],\n       [1.09453793, 1.4781484 ],\n       [1.08068535, 3.26432617],\n       [1.0749477 , 3.99010937],\n       [1.08614519, 1.64194425],\n       [1.09925597, 3.17902206],\n       [1.09562998, 3.75862945],\n       [1.08280952, 1.24464841],\n       [1.09449311, 2.41589237],\n       [1.07217139, 1.39762617],\n       [1.0816147 , 2.05817482],\n       [1.0917707 , 2.89853332],\n       [1.04567584, 2.06415849],\n       [1.09453793, 1.55899858],\n       [1.09396366, 1.57315382],\n       [1.07729904, 1.50046668],\n       [1.09688357, 1.96480443],\n       [1.07320725, 1.81535394],\n       [1.09925597, 2.74249555],\n       [1.08405464, 1.33973579],\n       [1.08614519, 2.06053736],\n       [1.09520394, 2.66806496],\n       [1.08429282, 2.19429641],\n       [1.09246065, 3.38320611],\n       [1.09453793, 2.06415849],\n       [1.07001844, 1.97453666],\n       [1.08106601, 3.99010937],\n       [1.09925597, 3.86919696],\n       [1.09672413, 3.38320611],\n       [1.09449311, 3.86919696],\n       [1.09479861, 3.26432617],\n       [1.060699  , 3.99010937],\n       [1.0874365 , 1.72612556],\n       [1.09925597, 3.20315925],\n       [1.07891757, 3.38320611],\n       [1.09324146, 2.03414263],\n       [1.08981276, 1.56289413],\n       [1.08981276, 1.06521614],\n       [1.0917707 , 2.66806496],\n       [1.09925597, 3.86919696],\n       [1.0823764 , 1.79914761],\n       [1.09246065, 2.40500997],\n       [1.08647034, 1.79914761],\n       [1.09925597, 3.86919696],\n       [1.09672413, 3.38320611],\n       [1.08420028, 1.60369671],\n       [1.09246065, 1.73578672],\n       [1.09688357, 3.99010937],\n       [1.02500775, 3.99010937],\n       [1.06347523, 3.99010937],\n       [1.0600782 , 3.99010937],\n       [1.04830644, 3.99010937],\n       [1.0812138 , 3.86919696],\n       [1.0701163 , 3.99010937],\n       [1.09703657, 3.86919696],\n       [1.08808592, 3.99010937],\n       [1.0797573 , 3.99010937],\n       [1.08894629, 3.26432617],\n       [1.0823764 , 2.89853332],\n       [1.09423918, 3.99010937],\n       [1.03083466, 3.17902206],\n       [1.08882172, 3.99010937],\n       [1.03070175, 3.97101793],\n       [1.08202735, 3.75862945],\n       [1.07891757, 3.99010937],\n       [1.06869354, 3.99010937],\n       [1.06916315, 3.86919696],\n       [1.01865816, 3.99010937],\n       [1.06105876, 3.86919696],\n       [1.08202735, 3.99010937],\n       [1.00885525, 3.99010937],\n       [1.07406757, 3.38320611],\n       [1.07920766, 3.99010937],\n       [1.09423918, 3.86919696],\n       [1.04830644, 3.99010937],\n       [1.08332761, 3.86919696],\n       [1.08222815, 3.38320611],\n       [1.08332761, 3.99010937],\n       [1.0797573 , 3.78035064],\n       [1.08446532, 3.86853089],\n       [1.07071294, 3.86919696],\n       [1.06421183, 2.60692251],\n       [1.09925597, 3.99010937],\n       [1.05751061, 3.86919696],\n       [1.08614519, 3.67827185],\n       [1.07891252, 3.99010937],\n       [1.07067708, 3.67827185],\n       [1.06526755, 3.99010937],\n       [1.04230066, 3.86919696],\n       [1.04924242, 3.99010937]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1.08333213, 1.68613451, 2.27113373, ..., 3.86919696, 3.86919696,\n       3.99010937])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "#1-ccs/cls\n",
    "cp_attr_contained_freq_items = copy.deepcopy(attributes_contained_in_freq_items)\n",
    "freq_count_per_trans_0 = np.matmul(tr_0_ary, attributes_contained_in_freq_items) # x_00\n",
    "freq_count_per_trans_1 = np.matmul(tr_1_ary, attributes_contained_in_freq_items) # x_01\n",
    "# Each element in the matrix indicates the count of how many times the corresponding\n",
    "# frequent itemset occurred in the transactions of the corresponding class.\n",
    "\n",
    "item_len = np.sum(attributes_contained_in_freq_items, axis=0) #item length\n",
    "cls0 = np.zeros(freq_itemsets_count)   #frequent_items['support']\n",
    "cls1 = np.zeros(freq_itemsets_count)\n",
    "conf = np.zeros(freq_itemsets_count)\n",
    "c_per_rule = np.zeros(freq_itemsets_count, dtype=int)\n",
    "cnt=0\n",
    "for i in range(freq_count_per_trans_0.shape[1]):\n",
    "    cls0[i] = (freq_count_per_trans_0[:, i] >= item_len[i]).sum() / freq_count_per_trans_0.shape[0]\n",
    "    cls1[i] = (freq_count_per_trans_1[:, i] >= item_len[i]).sum() / freq_count_per_trans_1.shape[0]\n",
    "    if cls1[i]/cls0[i]<1:\n",
    "        c_per_rule[i] = 0\n",
    "        conf[i] = 1- cls1[i]/cls0[i]\n",
    "        cnt = cnt +1\n",
    "    elif cls1[i]/cls0[i]>1:\n",
    "        c_per_rule[i] = 1\n",
    "        conf[i] = 1- cls0[i]/cls1[i]\n",
    "        cnt = cnt +1\n",
    "    else:\n",
    "        conf[i]=0\n",
    "        cp_attr_contained_freq_items[:, i]=0\n",
    "        c_per_rule[i] =-1\n",
    "print('class rules', cnt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(f\"Rules for class 0: {(c_per_rule == 0).sum()} Rules for class 1: {(c_per_rule == 1).sum()}\")\n",
    "print(f\"Avg conf for class 0: {conf[c_per_rule == 0].mean()}, Avg conf for class 1: {conf[c_per_rule == 1].mean()}\")\n",
    "\n",
    "te_0_ary=(transactions_te_0.values).astype('int')\n",
    "te_1_ary=(transactions_te_1.values).astype('int')\n",
    "\n",
    "#all matched rules  used\n",
    "y_0 = np.matmul(te_0_ary, cp_attr_contained_freq_items)\n",
    "y_1 = np.matmul(te_1_ary, cp_attr_contained_freq_items)\n",
    "\n",
    "pred = np.zeros((y_0.shape[0]+y_1.shape[0],2))\n",
    "cnt0=0\n",
    "cnt1=0\n",
    "\n",
    "for i in range(y_0.shape[0]):\n",
    "    cnt=0\n",
    "    for j in range(y_0.shape[1]):\n",
    "        if (c_per_rule[j]==0 and y_0[i,j]>=item_len[j]):\n",
    "            pred[i,0] = pred[i,0] + conf[j]\n",
    "            cnt = cnt+1\n",
    "    if (cnt==0):\n",
    "        cnt0 = cnt0+1\n",
    "    else:\n",
    "        pred[i,0] = pred[i,0]/cnt\n",
    "\n",
    "    cnt=0\n",
    "    for j in range(y_0.shape[1]):\n",
    "        if (c_per_rule[j]==1 and y_0[i,j]>=item_len[j]):\n",
    "            pred[i,1] = pred[i,1] + conf[j]\n",
    "            cnt = cnt+1\n",
    "\n",
    "    if (cnt==0):\n",
    "        cnt1 = cnt1+1\n",
    "    else:\n",
    "        pred[i,1] = pred[i,1]/cnt\n",
    "print(y_0.shape[0],cnt0, cnt1)\n",
    "\n",
    "cnt0=0\n",
    "cnt1=0\n",
    "for i in range(y_1.shape[0]):\n",
    "    cnt=0\n",
    "    x=0\n",
    "    for j in range(y_1.shape[1]):\n",
    "        if (c_per_rule[j]==0 and y_1[i,j]>=item_len[j]):\n",
    "            x = x + conf[j]\n",
    "            cnt = cnt+1\n",
    "    if (cnt==0):\n",
    "        cnt0 = cnt0+1\n",
    "    else:\n",
    "        pred[i+y_0.shape[0],0] = x/cnt\n",
    "\n",
    "    cnt=0\n",
    "    x=0\n",
    "    for j in range(y_1.shape[1]):\n",
    "        if (c_per_rule[j]==1 and y_1[i,j]>=item_len[j]):\n",
    "            x = x + conf[j]\n",
    "            cnt = cnt+1\n",
    "\n",
    "    if (cnt==0):\n",
    "        cnt1 = cnt1+1\n",
    "    else:\n",
    "        pred[i+y_0.shape[0],1] = x/cnt\n",
    "\n",
    "print(y_1.shape[0],cnt0, cnt1)\n",
    "\n",
    "y = np.concatenate((np.zeros(te_0_ary.shape[0]), np.ones(te_1_ary.shape[0])), axis=0)\n",
    "auc = roc_auc_score(y,pred[:,1])\n",
    "print(auc)\n",
    "y = np.concatenate((np.zeros(te_0_ary.shape[0]), np.ones(te_1_ary.shape[0])), axis=0)\n",
    "auc = roc_auc_score(y,-pred[:,0])\n",
    "print(auc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#all matched rules used for training data\n",
    "y_00 = np.matmul(tr_0_ary, cp_attr_contained_freq_items)\n",
    "y_01 = np.matmul(tr_1_ary, cp_attr_contained_freq_items)\n",
    "\n",
    "pred0 = np.zeros(y_00.shape[0]+y_01.shape[0])\n",
    "cnt0=0\n",
    "cnt1=0\n",
    "for i in range(y_00.shape[0]):\n",
    "\n",
    "    cnt=0\n",
    "    for j in range(y_00.shape[1]):\n",
    "        if (c_per_rule[j]==1 and y_00[i,j]>=item_len[j]):\n",
    "            pred0[i] = pred0[i] + conf[j]\n",
    "            cnt = cnt+1\n",
    "\n",
    "    if (cnt==0):\n",
    "        cnt1 = cnt1+1\n",
    "    else:\n",
    "        pred0[i] = pred0[i]/cnt\n",
    "\n",
    "cnt0=0\n",
    "cnt1=0\n",
    "for i in range(y_01.shape[0]):\n",
    "\n",
    "    cnt=0\n",
    "    for j in range(y_01.shape[1]):\n",
    "        if (c_per_rule[j]==1 and y_01[i,j]>=item_len[j]):\n",
    "            pred0[i + y_00.shape[0]] = pred0[i + y_00.shape[0]] + conf[j]\n",
    "            cnt = cnt+1\n",
    "\n",
    "    if (cnt==0):\n",
    "        cnt1 = cnt1+1\n",
    "    else:\n",
    "        pred0[i + y_00.shape[0]] = pred0[i + y_00.shape[0]] / cnt\n",
    "\n",
    "y0 = np.concatenate((np.zeros(tr_0_ary.shape[0]), np.ones(tr_1_ary.shape[0])), axis=0)\n",
    "\n",
    "z_1 = pred0[y0==1]\n",
    "m = np.mean(z_1)\n",
    "s = np.std(z_1)\n",
    "th = m\n",
    "\n",
    "pred_y = np.zeros(pred.shape[0], dtype=int)\n",
    "for i in range(pred.shape[0]):\n",
    "    if (pred[i,1]>=th):\n",
    "        pred_y[i]=1\n",
    "\n",
    "print(f1_score(y,pred_y))\n",
    "\n",
    "TP=0\n",
    "FP=0\n",
    "FN=0\n",
    "TN=0\n",
    "for i in range(pred.shape[0]):\n",
    "    if (y[i]==1 and pred_y[i]==1):\n",
    "        TP = TP+1\n",
    "    elif (y[i]==1 and pred_y[i]==0):\n",
    "        FN = FN+1\n",
    "    elif (y[i]==0 and pred_y[i]==1):\n",
    "        FP = FP+1\n",
    "    else:\n",
    "        TN = TN+1\n",
    "\n",
    "print('TP:', TP, 'FN:', FN)\n",
    "print('FP:', FP, 'TN:', TN)\n",
    "print('pre:', TP/(TP+FP), 'rec:', TP/(TP+FN))\n",
    "print('f1:', (2*TP)/(2*TP + FP + FN))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
